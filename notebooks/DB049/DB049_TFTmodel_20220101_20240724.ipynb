{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21435271",
   "metadata": {},
   "source": [
    "# LSTIDs Forecasting with the Temporal Fusion Transformer\n",
    "\n",
    "Author: Konstantinos Themelis\n",
    "\n",
    "\n",
    "This work is licensed under Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dbfca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler, MissingValuesFiller\n",
    "from darts.models import BlockRNNModel,TFTModel\n",
    "from darts.metrics import mape, mase, mae, mse, ope, r2_score, rmse, rmsle\n",
    "from darts.utils.likelihood_models import GaussianLikelihood\n",
    "from darts.utils.missing_values import extract_subseries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(14, 9)})\n",
    "\n",
    "import optuna\n",
    "\n",
    "import time # cpu time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44e69ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range(start, end):\n",
    "    start_date = datetime.strptime(start, '%Y-%m-%d').date()\n",
    "    end_date = datetime.strptime(end, '%Y-%m-%d').date()\n",
    "    delta = end_date - start_date \n",
    "    days = [start_date + timedelta(days=i) for i in range(delta.days + 1)]\n",
    "    return list(map(lambda n: n.strftime(\"%Y-%m-%d\"), days))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf28e6",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "241d2f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters\n",
    "station = 'DB049'\n",
    "data_path = f'../../datasets'\n",
    "model_path = f'../../models'\n",
    "day_start = '2022-01-01'\n",
    "day_end = '2024-07-24'\n",
    "\n",
    "dates_list = date_range(day_start, day_end)\n",
    "split_date = pd.Timestamp(\"20240601\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53017753",
   "metadata": {},
   "source": [
    "#### load SEC time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d82aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Dourbes data\n",
    "df_spcont1 = pd.read_csv(data_path + f'/{station}/oe_hfi_{station}_nearestfill_20220101_20230630.csv')\n",
    "df_spcont1['date'] = pd.to_datetime(df_spcont1['date']) \n",
    "# df_spcont = df_spcont[df_spcont.date <= datetime.strptime(day_end, '%Y-%m-%d')]\n",
    "# display(df_spcont1)\n",
    "\n",
    "# read techtide data\n",
    "df_spcont2 = pd.read_csv(data_path + f'/{station}/techtide_{station}_nearestfill_202208_202407.csv')\n",
    "df_spcont2['date'] = pd.to_datetime(df_spcont2['date']) \n",
    "# df_spcont = df_spcont[df_spcont.date <= datetime.strptime(day_end, '%Y-%m-%d')]\n",
    "# display(df_spcont2)\n",
    "\n",
    "# merge the two dataframes\n",
    "df_DB049 = pd.concat([df_spcont1[df_spcont1.date<'2023-01-01'], df_spcont2[df_spcont2.date>='2023-01-01']], ignore_index=True)\n",
    "df_DB049.rename(columns={\"spcont_filtered\": \"SEC_Durbes\"}, inplace=True)\n",
    "display(df_DB049)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802a71f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spcont time series \n",
    "ts_sec_Dourbes = TimeSeries.from_dataframe(df_DB049, time_col='date', value_cols='SEC_Durbes')\n",
    "ts_sec_Dourbes.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b828f4",
   "metadata": {},
   "source": [
    "#### load image indicators IL, IU and IE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198c954f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read fmi data\n",
    "csv_files = [data_path + f'/fmi/iliuie_{i}.csv' for i in dates_list]\n",
    "df_fmi = pd.concat(map(pd.read_csv, csv_files))\n",
    "df_fmi['date'] = pd.to_datetime(df_fmi['date']) \n",
    "df_fmi.drop(columns=['year', 'month', 'day', 'hour', 'minutes', 'second', 'la_IL', 'lo_IL', 'la_IU', 'lo_IU'], inplace=True)\n",
    "display(df_fmi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2045efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fmi input time series \n",
    "ts_IU = TimeSeries.from_dataframe(df_fmi, time_col='date', value_cols='IU')\n",
    "ts_IL = TimeSeries.from_dataframe(df_fmi, time_col='date', value_cols='IL')\n",
    "ts_IU.plot()\n",
    "ts_IL.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b403745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot fmi input time series \n",
    "ts_fmi = TimeSeries.from_dataframe(df_fmi, time_col='date', value_cols=['IL','IE','IU']) \n",
    "ts_fmi.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e6be39",
   "metadata": {},
   "source": [
    "#### load gnss tec gradient time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read gnss data\n",
    "csv_files = [data_path + f'/gnss/gnss_{i}.csv' for i in dates_list]\n",
    "\n",
    "# read csv files from list\n",
    "df_gnss = pd.concat(map(pd.read_csv, csv_files))\n",
    "\n",
    "# shift by 30sec to align with other measurements\n",
    "df_gnss['date'] = pd.to_datetime(df_gnss['date']) - timedelta(seconds=30)\n",
    "df_gnss.drop(columns=['id', 'pubid', 'product', 'activity', 'day'], inplace=True)\n",
    "if df_gnss.shape[0] < df_DB049.shape[0]:\n",
    "    df_tmp = pd.date_range(start=datetime.strptime(day_start, \"%Y-%m-%d\"), \n",
    "                     end=datetime.strptime(day_end, \"%Y-%m-%d\") + timedelta(hours=23) + timedelta(minutes=55), freq='5T')\\\n",
    "        .to_frame(index=False, name='date')\n",
    "    df_gnss = pd.merge(df_tmp, df_gnss, on='date', how='left')\n",
    "    #df_gnss['cvalue'] = df_gnss['cvalue'].interpolate(method='polynomial', order=2)\n",
    "# df_gnss.fillna(0, inplace=True)\n",
    "# df_gnss['cvalue'].clip(lower=0, inplace=True)\n",
    "display(df_gnss)\n",
    "\n",
    "# print((df_gnss['cvalue'] < 0).sum().sum(), df_gnss['cvalue'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eeae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot input gnss time series \n",
    "ts_gnss = TimeSeries.from_dataframe(df_gnss, time_col='date', value_cols='cvalue')\n",
    "ts_gnss.plot()\n",
    "plt.show()\n",
    "\n",
    "transformer = MissingValuesFiller()\n",
    "ts_gnss_filled = transformer.transform(ts_gnss)\n",
    "ts_gnss_filled.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c6979f",
   "metadata": {},
   "source": [
    "#### create time series from input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735ba68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge input dataframes\n",
    "df_spcont = df_DB049.copy()\n",
    "df_spcont.rename(columns={\"SEC_Durbes\": \"spcont_filtered\"}, inplace=True)\n",
    "df_all = df_spcont.merge(df_fmi, on='date', validate = 'one_to_one').merge(df_gnss, on='date', validate = 'one_to_one')\n",
    "df_all['spcont_filtered'] = df_all['spcont_filtered'].apply(lambda x: x if x >=0 else np.nan)\n",
    "df_all['hour'] = df_all['date'].dt.hour\n",
    "df_all['month'] = df_all['date'].dt.month\n",
    "df_all['mask'] = df_all['spcont_filtered'].apply(lambda x: True if x >=0 else False)\n",
    "display(df_all)\n",
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe77337",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create and fill target time series\n",
    "ts_spcont = TimeSeries.from_dataframe(df_all, \n",
    "                                      time_col='date',\n",
    "                                      value_cols=['spcont_filtered']\n",
    "                                     ) \n",
    "\n",
    "transformer_spcont = MissingValuesFiller()\n",
    "ts_spcont_filled = transformer_spcont.transform(ts_spcont)\n",
    "ts_spcont_filled.plot()\n",
    "plt.show()\n",
    "\n",
    "# create and fill past covariates\n",
    "ts_pastcovs = TimeSeries.from_dataframe(df_all,\n",
    "                                        time_col='date',\n",
    "                                        value_cols=['IL', 'IU', 'IE', 'cvalue'] \n",
    "                                       ) \n",
    "transformer_past = MissingValuesFiller()\n",
    "ts_pastcovs_filled = transformer_past.transform(ts_pastcovs)\n",
    "ts_pastcovs_filled.plot()\n",
    "plt.show()\n",
    "\n",
    "# create and fill future covariates\n",
    "ts_futcovs = TimeSeries.from_dataframe(df_all,\n",
    "                                       time_col='date',\n",
    "                                       value_cols=['hour', 'month']\n",
    "                                      ) \n",
    "ts_futcovs.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d926dc6",
   "metadata": {},
   "source": [
    "#### time series preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c975cf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_spcont, scaler_pastcovs, scaler_futcovs = Scaler(), Scaler(), Scaler()\n",
    "ts_spcont_scaled = scaler_spcont.fit_transform(ts_spcont_filled)\n",
    "ts_spcont_scaled.plot()\n",
    "plt.show()\n",
    "\n",
    "ts_pastcovs_scaled = scaler_pastcovs.fit_transform(ts_pastcovs_filled)\n",
    "ts_pastcovs_scaled.plot()\n",
    "plt.show()\n",
    "\n",
    "ts_futcovs_scaled = scaler_futcovs.fit_transform(ts_futcovs)\n",
    "ts_futcovs_scaled.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581e5ae",
   "metadata": {},
   "source": [
    "#### train / validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff5a0c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# split\n",
    "train_spcont, val_spcont = ts_spcont_scaled.split_after(split_date)\n",
    "train_spcont.plot()\n",
    "val_spcont.plot()\n",
    "plt.show()\n",
    "\n",
    "train_pastcovs, val_pastcovs = ts_pastcovs_scaled.split_after(split_date)\n",
    "train_pastcovs.plot()\n",
    "val_pastcovs.plot()\n",
    "plt.show()\n",
    "\n",
    "# train_futcovs, val_futcovs = ts_futcovs_scaled.split_after(split_date)\n",
    "# train_futcovs.plot()\n",
    "# val_futcovs.plot()\n",
    "# plt.show()\n",
    "\n",
    "# get valid samples indexes in validation set\n",
    "ts_mask = TimeSeries.from_dataframe(df_all, time_col='date', value_cols='mask')\n",
    "train_mask, val_mask = ts_mask.split_after(split_date)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521912eb",
   "metadata": {},
   "source": [
    "#### load / save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8c65fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tft_model = TFTModel.load(model_path + f'/{station}/TFTModel_hd82_ch50_drop0.02_ep256_ll2_batch1024_202301_202406.pt') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efdbea",
   "metadata": {},
   "source": [
    "#### evaluate performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "433f5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform prediction for marked days in validation set\n",
    "mark1 = pd.Timestamp('2024-06-15')\n",
    "mark2 = pd.Timestamp('2024-06-17')\n",
    "\n",
    "tft_model_predict = tft_model.historical_forecasts(series=val_spcont.slice(mark1-pd.Timedelta(minutes=250), mark2),\n",
    "                                                   past_covariates=val_pastcovs,\n",
    "                                                   future_covariates=ts_futcovs_scaled,\n",
    "                                                   start=None, \n",
    "                                                   num_samples=10,\n",
    "                                                   forecast_horizon=1,\n",
    "                                                   stride=1,\n",
    "                                                   retrain=False,\n",
    "                                                   verbose=False\n",
    "                                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4038efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def my_format_function(x, pos=None):\n",
    "    x = mdates.num2date(x)\n",
    "    if (pos %8 ==0):\n",
    "        fmt = '%Y-%m-%d %H:%M'\n",
    "    else:\n",
    "        fmt = '%H:%M'\n",
    "    label = x.strftime(fmt)\n",
    "    return label\n",
    "  \n",
    "theta = .7\n",
    "y_true = np.digitize(val_spcont.slice(mark1, mark2).values(), np.array([theta]), right=False)\n",
    "y_pred = np.digitize(tft_model_predict.slice(mark1, mark2).mean().values(), np.array([theta]), right=False)\n",
    "ts_true = TimeSeries.from_times_and_values(val_spcont.slice(mark1, mark2).time_index, 85*y_true)\n",
    "ts_pred = TimeSeries.from_times_and_values(val_spcont.slice(mark1, mark2).time_index, 85*y_pred)\n",
    "ts_pred_Dourbes = ts_pred.with_columns_renamed('0', 'predicted LSTID')\n",
    "\n",
    "\n",
    "day1 = mark1.strftime('%Y-%m-%d')\n",
    "day2 = mark2.strftime('%Y-%m-%d')\n",
    "sns.set_theme(style='white', font_scale=2)\n",
    "fig, axes = plt.subplots(3,1, sharex=True, layout=\"constrained\", figsize=(19,17))\n",
    "ts_IU.slice(mark1, mark2).plot(ax=axes[0], c='k')\n",
    "ts_IL.slice(mark1, mark2).plot(ax=axes[0], c='dimgrey')\n",
    "ts_gnss.slice(mark1, mark2).with_columns_renamed('cvalue', 'GNSS Grad Index').plot(ax=axes[1], c='g')\n",
    "axes[1].set(ylabel='mm/km')\n",
    "ts_sec_Dourbes.slice(mark1, mark2).plot(ax=axes[2])\n",
    "ts_pred_Dourbes.plot(ax=axes[2],c='r')\n",
    "axes[2].axhline(y=100*theta, linewidth=3, color='grey', label='LSTID threshold')\n",
    "axes[2].legend(loc='center right')\n",
    "axes[2].set(ylabel='SEC (%)')\n",
    "axes[0].set_title(f'Measurements from {day1} to {day2}')\n",
    "axes[0].set(xlabel=None)\n",
    "axes[0].set(ylabel='nT')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[1].set(xlabel=None)\n",
    "axes[2].set(xlabel='Time')\n",
    "#axes[2].xaxis.set_major_formatter(myFmt)\n",
    "locator = mdates.AutoDateLocator(minticks=20)\n",
    "locator.intervald[4] = [8] \n",
    "formatter = mdates.AutoDateFormatter(locator)\n",
    "formatter.scaled[1/(24)] = my_format_function\n",
    "axes[2].xaxis.set_ticks_position('bottom')\n",
    "axes[2].xaxis.set_major_locator(locator)\n",
    "axes[2].xaxis.set_major_formatter(formatter)\n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1913589",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf412e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iono",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
